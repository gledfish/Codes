# 机器学习
## 简介
机器学习是一种分析数据并学习预测结果的程序。
特点：数据集数量大

**数据集应该被分为训练集和测试集，80%用于训练，20%用于测试。**

## 回归问题 

简介：对输入数据进行预测，输出一个连续的数值。回归问题通常是基于历史数据训练一个回归模型，然后用于对新数据进行预测

常用算法：线性回归、岭回归、Lasso回归、随机森林回归等。

适用场景：房价预测，股票价格预测，人口增长预测，车辆油耗预测，购物车推荐。

### 线性回归
```python
import matplotlib.pyplot as plt
from scipy import stats

x = [5,7,8,7,2,17,2,9,4,11,12,9,6]
y = [99,86,87,88,111,86,103,87,94,78,77,85,86]

slope, intercept, r, p, std_err = stats.linregress(x, y) # 斜率，截距，相关系数，假设检验的p值, 标准差
def myfunc(x):
    return slope * x + intercept
mymodel = list(map(myfunc, x))
plt.scatter(x, y)
plt.plot(x, mymodel)
plt.show() # 画出有相关系数的散点图

speed = myfunc(10)
print(speed) # 预测车龄为 10 的车速度是多少
```



### 多项式回归

线性回归

```python
import numpy
import matplotlib.pyplot as plt

x = [89,43,36,36,95,10,66,34,38,20,26,29,48,64,6,5,36,66,72,40]
y = [21,46,3,35,67,95,53,72,58,10,26,34,90,33,38,20,56,2,47,15]

mymodel = numpy.poly1d(numpy.polyfit(x, y, 3)) # 创建多项式函数，并用最高次幂为 3 的函数拟合

myline = numpy.linspace(2, 95, 100) # 创建函数曲线对象

plt.scatter(x, y)
plt.plot(myline, mymodel(myline)) # 绘制函数曲线
plt.show()

# 查看拟合程度
print(r2_score(y, mymodel(x)))
```

### 多元回归

```python
import pandas as pd
from sklearn import linear_model

df = pd.read_csv('data.csv')

X = df['Weight', 'Volume']
y = df['CO2']

regr = linear_model.LinearRegression() # 创建多元回归模型
regr.fit(X, y)

predited_CO2 = regr.predict([[2300, 1300]]) # 预测结果
print(predictedCO2)

print(regr_coef_) # [0.00755095 0.00780526]
# 意思是 体重增加 1 kg，排放量增加0.00755095g
#       容量增加 1 cm^3，排放量增加0.00780526g

```
**比例缩放**

当单位不同一是，便需要将单位化为统一才能进行计算。一种方法是实用标准化方法（standardization method）

$$
z = (x - u) / s
$$
其中， z 是新值，x 是原始值， u 是平均值， s 是标准差

```python
import pandas  
from sklearn import linear_model
from sklearn.preprocessing import StandardScaler

scale = StandardScaler()

scaledX = scale.fit_transfrom(X)# X 将 x 缩放一个单位
    
 
```

```python	
import numpy
import matplotlib.pyplot as plt
numpy.random.seed(2)

x = numpy.random.normal(3, 1, 100)
y = numpy.random.normal(150, 40, 100) / x

train_x = x[:80] # 80% 用于训练
train_y = y[:80] 

test_x = x[80:] # 20% 用于测试
test_y = y[80:]

mymodel = numpy.poly1d(numpy.polyfit(train_x, train_y, 4))
muline = numpy.linespace(0,6,100)

plt.scatter(train_x, train_y)
plt.plot(myline, mymodel(myline))
plot.show() 

r2 = r2_score(train_y, mymodel(train_x)) # 计算拟合程度 0.799

r2 = r2_score(test_y, mymodel(test_x)) # 0.809

```

## 分类问题

简介：对输入数据进行分类，输出一个离散的类别标签。

常用算法：决策树、支持向量机、逻辑回归、朴素贝叶斯

适用场景：垃圾邮件过滤，图像识别，情感分析，信用评分，疾病诊断。

### KNN算法

如果待预测样本在特征空间中存在 K 个与其相邻的的样本，其中某一类别的样本数目较多，则待预测样本就属于这一类，并具有这个类别相关特性。

优点：无需估计参数，适用于解决分类问题

缺点：一个类的样本容量很大，而其他类样本容量很小时，有很能导致当输入一个新样本时，该样本的 K 个邻居中大容量类的样本占多数，而此时只依照数量的多少去预测未知样本的类型，就会可能增加预测错误概率。此时，我们就可以采用对样本取**“权值”**的方法来改进。

```
适用范围：KNN 分类算法适用于多分类问题、OCR光学模式识别、文本分类等领域。
```

```python
#加载红酒数据集
from sklearn.datasets import load_wine
#KNN分类算法
from sklearn.neighbors import KNeighborsClassifier
#分割训练集与测试集
from sklearn.model_selection import train_test_split
#导入numpy
import numpy as np
#加载数据集
wine_dataset=load_wine()
#查看数据集对应的键
print("红酒数据集的键:\n{}".format(wine_dataset.keys()))
print("数据集描述:\n{}".format(wine_dataset['data'].shape))
# data 为数据集数据;target 为样本标签
#分割数据集，比例为 训练集：测试集 = 8:2
X_train,X_test,y_train,y_test=train_test_split(wine_dataset['data'],wine_dataset['target'],test_size=0.2,random_state=0)
#构建knn分类模型，并指定 k 值
KNN=KNeighborsClassifier(n_neighbors=10)
#使用训练集训练模型
KNN.fit(X_train,y_train)
#评估模型的得分
score=KNN.score(X_test,y_test)
print(score)
#给出一组数据对酒进行分类
X_wine_test=np.array([[11.8,4.39,2.39,29,82,2.86,3.53,0.21,2.85,2.8,.75,3.78,490]])
predict_result=KNN.predict(X_wine_test)
print(predict_result)
print("分类结果：{}".format(wine_dataset['target_names'][predict_result]))
```

```bash
红酒数据集的键:
dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])
数据集描述:
(178, 13)
0.75
[1]
分类结果：['class_1']
```

### 朴素贝叶斯公式

```python
#鸢尾花数据集
from sklearn.datasets import load_iris

#导入朴素贝叶斯模型，这里选用高斯分类器
from sklearn.naive_bayes import GaussianNB

#载入数据集
X,y=load_iris(return_X_y=True)
bayes_modle=GaussianNB()

#训练数据
bayes_modle.fit(X,y)

#使用模型进行分类预测
result=bayes_modle.predict(X)
print(result)
#对模型评分

model_score=bayes_modle.score(X,y)
print(model_score)
```



### 线性分类器

### 逻辑回归

Logistic 算法适用于分类问题，该算法在处理二分类问题上表现优越，但在多分类（二个以上）问题上容易出现欠拟合。Logistic 算法除了适用于回归分类问题，还可以作为神经网络算法的激活函数（即 Sigmoid 函数）

```python
#logistic算法
#从 scikit-learn库导入线性模型中的logistic回归算法

from sklearn.linear_model import LogisticRegression

#导入sklearn 中的自带数据集 鸢尾花数据集
from sklearn.datasets import load_iris

# skleran 提供的分割数据集的方法
from sklearn.model_selection import train_test_split

#载入鸢尾花数据集
iris_dataset=load_iris()

# data 数组的每一行对应一朵花，列代表每朵花的四个测量数据，分别是：花瓣的长度，宽度，花萼的长度、宽度
print("data数组类型: {}".format(type(iris_dataset['data'])))

# 前五朵花的数据
print("前五朵花数据:\n{}".format(iris_dataset['data'][:5]))

#分割数据集训练集，测试集
X_train,X_test,Y_train,Y_test=train_test_split(iris_dataset['data'],iris_dataset['target'],random_state=0)

#训练模型
#设置最大迭代次数为3000，默认为1000.不更改会出现警告提示
log_reg = LogisticRegression(max_iter=3000)

#给模型喂入数据
clm=log_reg.fit(X_train,Y_train)

#使用模型对测试集分类预测,并打印分类结果
print(clm.predict(X_test))

#最后使用性能评估器，测试模型优良，用测试集对模型进行评分
print(clm.score(X_test,Y_test))
```



**感知器**

### 支持向量机

### **二次分类器**

### 核估计

### Boosting算法

### 决策树

决策树用于预测人是否会做出某种决定，它往往与许多因素有关，考虑时要综合考虑。



**决策树不能比较非数值数据**，计算时，需要将非数值数据转换成数值数据。



决策树是一个二叉树，如何将二叉树分开，有很多种方法，一种方法是使用**GiNi**方法
$$
Gini = 1 - (x/n)^2 + (y/n)^2
$$
x，y是分支样本数量，n 是总样本数量。当 GiNi = 0.0 时，表示该分支所有样本都得到了相同的结果。

***分割样本的方法***

* C4.5算法：使用信息增益比（Gain Ratio）来选择最优特征进行分割，它考虑了特征取值个数的影响，减轻了ID3算法偏向于取值多的特征的问题。

* GINI算法：可以处理连续值的特征，还可以用于回归问题。

* CHAID 算法：基于卡方检验（Chi-Square Test）选择最优特征进行分割，它可以处理离散值和有序离散值的特征，但是不适用于连续值特征

```python

from sklearn import tree
import matplotlib.pyplot as plt
import pandas
from sklearn import DecisionTreeClassifier

# 读取数据
df = pd.read_csv('data.csv')

# 处理非数字值
d = {'UK':0, 'USA':1, 'N':2}
df['Nationality'] = df['Nationality'].map(d)
d = {'YES':1, 'NO':0}
df['GO'] = df['GO'].map(d)

# 特征值
features = ['Age', 'Experience', 'Rank', 'Nationality']
X = df[features]
y = df['Go']

dtree = DecisionTreeClassifier()
dtree = dtree.fit(X, y)

tree.plot_tree(dtree, feature_names=features)
```

![img_ml_decision_tree.png](https://s2.loli.net/2023/03/28/q8UDdPHhztW913w.png)



### 神经网络

### 学习式向量量化



## 聚类问题

**K-means聚类算法** 

K-means 就是一种采用了划分法的聚类算法，预先设定 K 个簇，means 表示均值。K-means 聚类算法的聚类过程，可以看成是不断寻找簇的质心的过程，这个过程从随机设定 K 个质心开始，直到找到 K 个真正质心为止。

## 异常检测问题

## 关联规则问题

## 推荐系统问题

## 强化学习问题





